{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KrghWnqx7BpQ",
    "outputId": "2d476afa-0d03-4223-d634-dbbd0a7b9f76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/afareen/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /Users/afareen/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "#nltk.download('stopwords')\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VHFbvb3Q7BpU"
   },
   "outputs": [],
   "source": [
    "def get_all_data():\n",
    "    dataTrue = pd.read_csv('True.csv')\n",
    "    dataTrue['Label'] = 0 #not fake news\n",
    "    dataFalse = pd.read_csv('Fake.csv')\n",
    "    dataFalse['Label'] = 1 #fake news\n",
    "    list = [dataTrue,dataFalse]\n",
    "    data = pd.concat(list).reset_index(drop=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "LeRMCRH27BpY"
   },
   "outputs": [],
   "source": [
    "#get rid of uppercase, new lines, non-alphabetical characters\n",
    "def preprocess_data(data):\n",
    "    for i in range(len(data)):\n",
    "        if i%100 == 0: \n",
    "            print(i)\n",
    "        title_temp = data['title'][i].lower()\n",
    "        title_temp = title_temp.replace('\\n',' ')\n",
    "        title_temp = ''.join(c for c in title_temp if c.isalpha() | (c == ' '))\n",
    "        #print(title_temp)\n",
    "        text_temp = data['text'][i].lower()\n",
    "        text_temp = text_temp.replace('\\n',' ')\n",
    "        text_temp = ''.join(c for c in text_temp if c.isalpha() | (c == ' '))\n",
    "        tokens_title = word_tokenize(title_temp)\n",
    "        tokens_temp = word_tokenize(text_temp)\n",
    "        tokens = tokens_title + tokens_temp \n",
    "#         no_stopwords = [word for word in tokens if not word in stopwords.words()]\n",
    "#         data['text'][i] = no_stopwords\n",
    "        data['text'][i] = tokens\n",
    "        #print(data['text'][i])\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y6U-cTXP7Bpb",
    "outputId": "7b04efb6-e453-4917-9475-e8a99df0d9a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "22000\n",
      "22100\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "22800\n",
      "22900\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n",
      "23700\n",
      "23800\n",
      "23900\n",
      "24000\n",
      "24100\n",
      "24200\n",
      "24300\n",
      "24400\n",
      "24500\n",
      "24600\n",
      "24700\n",
      "24800\n",
      "24900\n",
      "25000\n",
      "25100\n",
      "25200\n",
      "25300\n",
      "25400\n",
      "25500\n",
      "25600\n",
      "25700\n",
      "25800\n",
      "25900\n",
      "26000\n",
      "26100\n",
      "26200\n",
      "26300\n",
      "26400\n",
      "26500\n",
      "26600\n",
      "26700\n",
      "26800\n",
      "26900\n",
      "27000\n",
      "27100\n",
      "27200\n",
      "27300\n",
      "27400\n",
      "27500\n",
      "27600\n",
      "27700\n",
      "27800\n",
      "27900\n",
      "28000\n",
      "28100\n",
      "28200\n",
      "28300\n",
      "28400\n",
      "28500\n",
      "28600\n",
      "28700\n",
      "28800\n",
      "28900\n",
      "29000\n",
      "29100\n",
      "29200\n",
      "29300\n",
      "29400\n",
      "29500\n",
      "29600\n",
      "29700\n",
      "29800\n",
      "29900\n",
      "30000\n",
      "30100\n",
      "30200\n",
      "30300\n",
      "30400\n",
      "30500\n",
      "30600\n",
      "30700\n",
      "30800\n",
      "30900\n",
      "31000\n",
      "31100\n",
      "31200\n",
      "31300\n",
      "31400\n",
      "31500\n",
      "31600\n",
      "31700\n",
      "31800\n",
      "31900\n",
      "32000\n",
      "32100\n",
      "32200\n",
      "32300\n",
      "32400\n",
      "32500\n",
      "32600\n",
      "32700\n",
      "32800\n",
      "32900\n",
      "33000\n",
      "33100\n",
      "33200\n",
      "33300\n",
      "33400\n",
      "33500\n",
      "33600\n",
      "33700\n",
      "33800\n",
      "33900\n",
      "34000\n",
      "34100\n",
      "34200\n",
      "34300\n",
      "34400\n",
      "34500\n",
      "34600\n",
      "34700\n",
      "34800\n",
      "34900\n",
      "35000\n",
      "35100\n",
      "35200\n",
      "35300\n",
      "35400\n",
      "35500\n",
      "35600\n",
      "35700\n",
      "35800\n",
      "35900\n",
      "36000\n",
      "36100\n",
      "36200\n",
      "36300\n",
      "36400\n",
      "36500\n",
      "36600\n",
      "36700\n",
      "36800\n",
      "36900\n",
      "37000\n",
      "37100\n",
      "37200\n",
      "37300\n",
      "37400\n",
      "37500\n",
      "37600\n",
      "37700\n",
      "37800\n",
      "37900\n",
      "38000\n",
      "38100\n",
      "38200\n",
      "38300\n",
      "38400\n",
      "38500\n",
      "38600\n",
      "38700\n",
      "38800\n",
      "38900\n",
      "39000\n",
      "39100\n",
      "39200\n",
      "39300\n",
      "39400\n",
      "39500\n",
      "39600\n",
      "39700\n",
      "39800\n",
      "39900\n",
      "40000\n",
      "40100\n",
      "40200\n",
      "40300\n",
      "40400\n",
      "40500\n",
      "40600\n",
      "40700\n",
      "40800\n",
      "40900\n",
      "41000\n",
      "41100\n",
      "41200\n",
      "41300\n",
      "41400\n",
      "41500\n",
      "41600\n",
      "41700\n",
      "41800\n",
      "41900\n",
      "42000\n",
      "42100\n",
      "42200\n",
      "42300\n",
      "42400\n",
      "42500\n",
      "42600\n",
      "42700\n",
      "42800\n",
      "42900\n",
      "43000\n",
      "43100\n",
      "43200\n",
      "43300\n",
      "43400\n",
      "43500\n",
      "43600\n",
      "43700\n",
      "43800\n",
      "43900\n",
      "44000\n",
      "44100\n",
      "44200\n",
      "44300\n",
      "44400\n",
      "44500\n",
      "44600\n",
      "44700\n",
      "44800\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>[as, us, budget, fight, looms, republicans, fl...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>[us, military, to, accept, transgender, recrui...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>[senior, us, republican, senator, let, mr, mue...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>[fbi, russia, probe, helped, by, australian, d...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>[trump, wants, postal, service, to, charge, mu...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  [as, us, budget, fight, looms, republicans, fl...  politicsNews   \n",
       "1  [us, military, to, accept, transgender, recrui...  politicsNews   \n",
       "2  [senior, us, republican, senator, let, mr, mue...  politicsNews   \n",
       "3  [fbi, russia, probe, helped, by, australian, d...  politicsNews   \n",
       "4  [trump, wants, postal, service, to, charge, mu...  politicsNews   \n",
       "\n",
       "                 date  Label  \n",
       "0  December 31, 2017       0  \n",
       "1  December 29, 2017       0  \n",
       "2  December 31, 2017       0  \n",
       "3  December 30, 2017       0  \n",
       "4  December 29, 2017       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullDataset = get_all_data()\n",
    "fixedDataset = preprocess_data(fullDataset)\n",
    "fixedDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "EZyQZeLt7Bpd"
   },
   "outputs": [],
   "source": [
    "fixedDataset.to_csv('Cleaned-Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tfdHFMKK7Bpg",
    "outputId": "af7f7309-c3ed-46a2-d854-b7c3988eaf7f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[as, us, budget, fight, looms, republicans, fl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[us, military, to, accept, transgender, recrui...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[senior, us, republican, senator, let, mr, mue...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[fbi, russia, probe, helped, by, australian, d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[trump, wants, postal, service, to, charge, mu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  Label\n",
       "0  [as, us, budget, fight, looms, republicans, fl...      0\n",
       "1  [us, military, to, accept, transgender, recrui...      0\n",
       "2  [senior, us, republican, senator, let, mr, mue...      0\n",
       "3  [fbi, russia, probe, helped, by, australian, d...      0\n",
       "4  [trump, wants, postal, service, to, charge, mu...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_data = fixedDataset[['text','Label']]\n",
    "relevant_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LF6RrBXi7Bpi",
    "outputId": "f7355880-104c-4cc0-db6c-f30dec4ece2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  Label\n",
      "0  [as, us, budget, fight, looms, republicans, fl...      0\n",
      "1  [us, military, to, accept, transgender, recrui...      0\n",
      "2  [senior, us, republican, senator, let, mr, mue...      0\n",
      "3  [trump, wants, postal, service, to, charge, mu...      0\n",
      "4  [white, house, congress, prepare, for, talks, ...      0\n",
      "35870\n",
      "                                                text  Label\n",
      "0  [fbi, russia, probe, helped, by, australian, d...      0\n",
      "1  [trump, says, russia, probe, will, be, fair, b...      0\n",
      "2  [factbox, trump, on, twitter, dec, approval, r...      0\n",
      "3  [alabama, official, to, certify, senatorelect,...      0\n",
      "4  [new, york, governor, questions, the, constitu...      0\n",
      "9028\n"
     ]
    }
   ],
   "source": [
    "train_indices = np.random.rand(len(relevant_data)) < 0.8\n",
    "train = relevant_data[train_indices].reset_index(drop=True)\n",
    "test = relevant_data[~train_indices].reset_index(drop=True)\n",
    "print(train.head())\n",
    "print(len(train))\n",
    "print(test.head())\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "B6nUsUc07Bpn"
   },
   "outputs": [],
   "source": [
    "#train model\n",
    "def training_step(training_data, vectorizer):\n",
    "    training_text = []\n",
    "    training_result = []\n",
    "    for i in range(len(training_data)):\n",
    "        #training_text.append(training_data['text'][i])\n",
    "        training_text.append(' '.join(str(x) for x in training_data['text'][i]))\n",
    "        training_result.append(training_data['Label'][i])\n",
    "    training_text = vectorizer.fit_transform(training_text)   \n",
    "    classifier = MultinomialNB().fit(training_text, training_result) #remove toarray for bernoulli/multi\n",
    "#     print(\"Classifier: \" + str(classifier))\n",
    "#     print(\"Classifier log prior: \" + str(classifier.class_log_prior_))\n",
    "#     print(\"Feature log prob: \" + str(classifier.feature_log_prob_))\n",
    "    classifier.get_params()\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VFkqkY7_7Bpr"
   },
   "outputs": [],
   "source": [
    "#return block of text and its classifier prediction\n",
    "def analyze_text(classifier, vectorizer, text):\n",
    "#     print(\"Classifier prediction: \" + str(classifier.predict(vectorizer.transform([text]))))\n",
    "    return text, classifier.predict(vectorizer.transform([text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "WBqxGtLm7Bpt"
   },
   "outputs": [],
   "source": [
    "#evaluate model performance\n",
    "def evaluate(evaluation_data, vectorizer):\n",
    "    evaluation_text = []\n",
    "    evaluation_result = []\n",
    "    #separate features/labels\n",
    "    for i in range(len(evaluation_data)):\n",
    "        #training_text.append(training_data['text'][i])\n",
    "        evaluation_text.append(' '.join(str(x) for x in evaluation_data['text'][i]))\n",
    "        evaluation_result.append(evaluation_data['Label'][i])\n",
    "    #check accuracy of classifier on evaluation data\n",
    "    total = len(evaluation_text)\n",
    "    corrects = 0\n",
    "    for i in range(0, total):\n",
    "        result = classifier.predict(vectorizer.transform([evaluation_text[i]])) #remove toarray\n",
    "        text = evaluation_text[i]\n",
    "        corrects += 1 if result[0] == evaluation_result[i] else 0\n",
    "    print(\"Accuracy: \", corrects * 100 / total)\n",
    "    return corrects * 100 / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBjydss37Bpw",
    "outputId": "bfcc5aed-de19-4879-859e-be68a9906cd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  96.24501550731058\n",
      "96.24501550731058\n"
     ]
    }
   ],
   "source": [
    "v = CountVectorizer('binary=true')\n",
    "classifier = training_step(train, v)\n",
    "acc = evaluate(test, v)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "YZTOpfNh7Bpy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Real-vs-Fake-News-Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
